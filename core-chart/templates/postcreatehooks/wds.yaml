{{- if .Values.InstallPCHs }}
apiVersion: tenancy.kflex.kubestellar.org/v1alpha1
kind: PostCreateHook
metadata:
  name: wds
  labels:
    kflex.kubestellar.io/cptype: wds
spec:
  templates:

  # vvvv TRANSPORT CONTROLLER vvvv
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: "{{"{{.ControlPlaneName}}-transport-controller"}}"
    rules:
    - apiGroups:
      - ""
      resources:
      - secrets
      verbs:
      - get
      - list
      - watch
    - apiGroups:
      - tenancy.kflex.kubestellar.org
      resources:
      - controlplanes
      verbs:
      - get
      - list
      - watch
    - apiGroups:
      - tenancy.kflex.kubestellar.org
      resources:
      - controlplanes/status
      verbs:
      - get
      - patch
      - update
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: "{{"{{.ControlPlaneName}}"}}-transport-controller"
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: "{{"{{.ControlPlaneName}}"}}-transport-controller"
    subjects:
    - kind: ServiceAccount
      name: default
      namespace: "{{"{{.Namespace}}"}}"
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: transport-controller-config
    data:
      get-kubeconfig.sh: |
        #!/bin/env bash
        # Get the in-cluster kubeconfig for KubeFlex Control Planes
        # get-kubeconfig.sh cp_name guess_its_name

        # input parameters
        cp_name="${1%"-system"}" # cp name or cp namespace
        guess_its_name="$2" # true: try guessing the name of the ITS CP

        # check if the CP name is valid or needs to be guessed
        while [ "$cp_name" == "" ] ; do
          if [ "$guess_its_name" == "true" ] ; then
            cps=$(kubectl get controlplane -l 'kflex.kubestellar.io/cptype=its' 2> /dev/null | tail -n +2)
            case $(echo -n "$cps" | grep -c '^') in
              (0)
                >&2 echo "Waiting for an ITS control plane to exist..."
                sleep 10;;
              (1)
                cp_name="${cps%% *}"
                break;;
              (*)
                >&2 echo "ERROR: found more than one Control Plane of type its!"
                exit 1;;
            esac
          else
            >&2 echo "ERROR: no Control Plane name specified!"
            exit 3
          fi
        done

        # wait for the CP to exists and be ready
        while [[ $(kubectl get controlplane "$cp_name" -o 'jsonpath={..status.conditions[?(@.type=="Ready")].status}') != "True" ]]; do
          >&2 echo "Waiting for \"$cp_name\" control plane to exist and be ready..."
          sleep 10
        done

        # determine the secret name and namespace
        key=$(kubectl get controlplane $cp_name -o=jsonpath='{.status.secretRef.inClusterKey}')
        secret_name=$(kubectl get controlplane $cp_name -o=jsonpath='{.status.secretRef.name}')
        secret_namespace=$(kubectl get controlplane $cp_name -o=jsonpath='{.status.secretRef.namespace}')

        # get the kubeconfig in base64
        >&2 echo "Getting \"$key\" from \"$secret_name\" secret in \"$secret_namespace\" for control plane \"$cp_name\"..."
        kubectl get secret $secret_name -n $secret_namespace -o=jsonpath="{.data.$key}"
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: transport-controller
    spec:
      replicas: 1
      selector:
        matchLabels:
          name: transport-controller
      template:
        metadata:
          labels:
            name: transport-controller
        spec:
          initContainers:
          - name: setup-wds-kubeconfig
            image: quay.io/kubestellar/kubectl:{{.Values.KUBECTL_VERSION}}
            imagePullPolicy: IfNotPresent
            command: [ "bin/sh", "-c", "sh /mnt/config/get-kubeconfig.sh '{{"{{.ControlPlaneName}}"}}' false | base64 -d > /mnt/shared/wds-kubeconfig" ]
            volumeMounts:
            - name: config-volume
              mountPath: /mnt/config
            - name: shared-volume
              mountPath: /mnt/shared
          - name: setup-its-kubeconfig
            image: quay.io/kubestellar/kubectl:{{.Values.KUBECTL_VERSION}}
            imagePullPolicy: IfNotPresent
            command: [ "bin/sh", "-c", "sh /mnt/config/get-kubeconfig.sh '{{.ITSName}}' true | base64 -d > /mnt/shared/transport-kubeconfig" ]
            volumeMounts:
            - name: config-volume
              mountPath: /mnt/config
            - name: shared-volume
              mountPath: /mnt/shared
          containers:
          - name: transport-controller
            image: ghcr.io/kubestellar/kubestellar/ocm-transport-controller:{{ .Values.TRANSPORT_VERSION | default .Values.KUBESTELLAR_VERSION }}
            imagePullPolicy: IfNotPresent
            args:
            - --metrics-bind-address={{.Values.transport_controller.metrics_bind_addr}}
            - --pprof-bind-address={{.Values.transport_controller.pprof_bind_addr}}
            - --transport-kubeconfig=/mnt/shared/transport-kubeconfig
            - --transport-qps={{.Values.transport_controller.transport_qps}}
            - --transport-burst={{.Values.transport_controller.transport_burst}}
            - --wds-kubeconfig=/mnt/shared/wds-kubeconfig
            - --wds-name={{"{{.ControlPlaneName}}"}}
            - --wds-qps={{.Values.transport_controller.wds_qps}}
            - --wds-burst={{.Values.transport_controller.wds_burst}}
            - -v={{.Values.verbosity.transport | default .Values.verbosity.default | default 4 }}
            - --max-num-wrapped={{.Values.transport_controller.max_num_wrapped}}
            - --max-size-wrapped={{.Values.transport_controller.max_size_wrapped}}
            volumeMounts:
            - name: shared-volume
              mountPath: /mnt/shared
              readOnly: true
          volumes:
          - name: shared-volume
            emptyDir: {}
          - name: config-volume
            configMap:
              name: transport-controller-config
              defaultMode: 0744
  # ^^^^ TRANSPORT CONTROLLER ^^^^

  # vvvv KUBESTELLAR CONTROLLER vvvv
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: kubestellar-leader-election-role
    rules:
      - apiGroups:
          - ""
        resources:
          - configmaps
        verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
      - apiGroups:
          - coordination.k8s.io
        resources:
          - leases
        verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
      - apiGroups:
          - ""
        resources:
          - events
        verbs:
          - create
          - patch
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      creationTimestamp: null
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-manager-role'
    rules:
      - apiGroups:
          - ""
        resources:
          - secrets
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - tenancy.kflex.kubestellar.org
        resources:
          - controlplanes
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - tenancy.kflex.kubestellar.org
        resources:
          - controlplanes/status
        verbs:
          - get
          - patch
          - update
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-metrics-reader'
    rules:
      - nonResourceURLs:
          - /metrics
        verbs:
          - get
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      labels:
        app.kubernetes.io/component: kube-rbac-proxy
        app.kubernetes.io/created-by: kubestellar
        app.kubernetes.io/instance: proxy-role
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/name: clusterrole
        app.kubernetes.io/part-of: kubestellar
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-proxy-role'
    rules:
      - apiGroups:
          - authentication.k8s.io
        resources:
          - tokenreviews
        verbs:
          - create
      - apiGroups:
          - authorization.k8s.io
        resources:
          - subjectaccessreviews
        verbs:
          - create
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: kubestellar-leader-election-rolebinding
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: kubestellar-leader-election-role
    subjects:
      - kind: ServiceAccount
        name: default
        namespace: '{{"{{.Namespace}}"}}'
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      labels:
        app.kubernetes.io/component: rbac
        app.kubernetes.io/created-by: kubestellar
        app.kubernetes.io/instance: manager-rolebinding
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/name: clusterrolebinding
        app.kubernetes.io/part-of: kubestellar
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-manager-rolebinding'
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-manager-role'
    subjects:
      - kind: ServiceAccount
        name: default
        namespace: '{{"{{.Namespace}}"}}'
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      labels:
        app.kubernetes.io/component: kube-rbac-proxy
        app.kubernetes.io/created-by: kubestellar
        app.kubernetes.io/instance: proxy-rolebinding
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/name: clusterrolebinding
        app.kubernetes.io/part-of: kubestellar
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-proxy-rolebinding'
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: '{{"{{.ControlPlaneName}}"}}-kubestellar-proxy-role'
    subjects:
      - kind: ServiceAccount
        name: default
        namespace: '{{"{{.Namespace}}"}}'
  - apiVersion: v1
    data: {}
    kind: ConfigMap
    metadata:
      name: kubestellar-config
  - apiVersion: v1
    kind: Service
    metadata:
      labels:
        control-plane: controller-manager
      name: kubestellar-controller-manager-metrics-service
    spec:
      ports:
        - name: metrics
          port: 8443
          protocol: TCP
          targetPort: metrics
      selector:
        control-plane: controller-manager
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        control-plane: controller-manager
      name: kubestellar-controller-manager
    spec:
      replicas: 1
      selector:
        matchLabels:
          control-plane: controller-manager
      template:
        metadata:
          annotations:
            kubectl.kubernetes.io/default-container: manager
          labels:
            control-plane: controller-manager
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: kubernetes.io/arch
                        operator: In
                        values:
                          - amd64
                          - arm64
                          - ppc64le
                          - s390x
                      - key: kubernetes.io/os
                        operator: In
                        values:
                          - linux
          containers:
            - args:
                - --secure-listen-address=0.0.0.0:8443
                - --upstream=http://127.0.0.1:8080/
                - --logtostderr=true
                - --v=0
              image: gcr.io/kubebuilder/kube-rbac-proxy:v0.13.1
              name: kube-rbac-proxy
              ports:
                - containerPort: 8443
                  name: metrics
                  protocol: TCP
              resources:
                limits:
                  cpu: 500m
                  memory: 128Mi
                requests:
                  cpu: 5m
                  memory: 64Mi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
            - args:
                - --health-probe-bind-address=:8081
                - --metrics-bind-address=127.0.0.1:8080
                - --pprof-bind-address=:8082
                - --leader-elect
                - --wds-name={{"{{.ControlPlaneName}}"}}
                - --its-name={{"{{.ITSName}}"}}
                - --api-groups={{"{{.APIGroups}}"}}
                - -v={{.Values.verbosity.kubestellar | default .Values.verbosity.default | default 2 }}
              image: ghcr.io/kubestellar/kubestellar/controller-manager:{{.Values.KUBESTELLAR_VERSION}}
              imagePullPolicy: IfNotPresent
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: 8081
                initialDelaySeconds: 15
                periodSeconds: 20
              name: manager
              ports:
                - containerPort: 8082
                  name: debug-pprof
                  protocol: TCP
              readinessProbe:
                httpGet:
                  path: /readyz
                  port: 8081
                initialDelaySeconds: 5
                periodSeconds: 10
              resources:
                limits:
                  cpu: 500m
                  memory: 1Gi
                requests:
                  cpu: 10m
                  memory: 64Mi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
          securityContext:
            runAsNonRoot: true
          terminationGracePeriodSeconds: 10
  # ^^^^ KUBESTELLAR CONTROLLER ^^^^

{{- end }}
